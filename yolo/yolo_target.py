"""Target generators for YOLOs."""
# pylint: disable=arguments-differ, unsupported-assignment-operation
from __future__ import absolute_import
from __future__ import division

import numpy as np
from mxnet import gluon
from mxnet import nd
from mxnet import autograd
from ...nn.bbox import BBoxCornerToCenter, BBoxCenterToCorner, BBoxBatchIOU

class YOLOV3PrefetchTargetGenerator(gluon.Block):
    """YOLO V3 prefetch target generator.
    The target generated by this instance is invariant to network predictions.
    Therefore it is usually used in DataLoader transform function to reduce the load on GPUs.

    Parameters
    ----------
    num_class : int
        Number of foreground classes.

    """
    def __init__(self, num_class, **kwargs):
        super(YOLOV3PrefetchTargetGenerator, self).__init__(**kwargs)
        self._num_class = num_class
        self.bbox2center = BBoxCornerToCenter(axis=-1, split=True)  # 转换为四角坐标
        self.bbox2cornerbbox2corner = BBoxCenterToCorner(axis=-1, split=False) # 转换为中心坐标

    def forward(self, img, xs, anchors, offsets, gt_boxes, gt_ids, gt_mixratio=None):
        """Generating training targets that do not require network predictions.

        Parameters
        self._fake_x, self._feat_maps, self._anchors, self._offsets,
        ----------
        img : mxnet.nd.NDArray
            Original image tensor.      img = mx.nd.zeros((1, 3, 416, 416))   
        xs : list of mxnet.nd.NDArray   [[13, 13], [26, 26], [52, 52]]
            List of feature maps. 
        anchors : mxnet.nd.NDArray      [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]] 
            YOLO3 anchors.
        offsets : mxnet.nd.NDArray      [[1, 13*13,1,2], [1, 26*26,1,2], [1, 52*52,1,2]]
            Pre-generated x and y offsets for YOLO3.   
            # 相对的是grid cell左上角的偏移量
      
        gt_boxes : mxnet.nd.NDArray
            Ground-truth boxes.
        gt_ids : mxnet.nd.NDArray
            Ground-truth IDs. 
        gt_mixratio : mxnet.nd.NDArray, optional
            Mixup ratio from 0 to 1.
        
        _fake_x  shape : [1, 3, 416, 416]  # img
        都是list类型
        feat_maps:[                         # xs
                (1, 1, 13, 13)
                (1, 1, 26, 26)
                (1, 1, 52, 52)]
        anchors:[
                (1, 1, 3, 2)     # 13 * 13
                (1, 1, 3, 2)     # 26 * 26 
                (1, 1, 3, 2)     # 52 * 53]

        offsets:[
                (1, 169,  1, 2)   # 13 * 13
                (1, 676,  1, 2)   # 26 * 26
                (1, 2704, 1, 2)   # 52 * 53]

         gt_boxes    = train_dataset[0][1] [np.newaxis, :, :4]) [B,M,4]
         gt_ids      = train_dataset[0][1] [np.newaxis, :, :4:5])
         gt_mixratio = train_dataset[0][1] [np.newaxis, :, -1:])

        Returns
        -------
        # 需要生成的因素
        (tuple of) mxnet.nd.NDArray
            objectness: 0 for negative, 1 for positive, -1 for ignore.
            center_targets: regression target for center x and y.
            scale_targets: regression target for scale x and y.
            weights: element-wise gradient weights for center_targets and scale_targets.
            class_targets: a one-hot vector for classification.


        self._target_generator(
            self._fake_x, self._feat_maps, self._anchors, self._offsets,
            gt_bboxes, gt_ids, gt_mixratio)


        anchors_lst = [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]
        anchors = [nd.array(a) for a in anchors_lst] 
        
        offsets = [ nd.arange(13*13*2).reshape(1,13*13, 1, 2),
            nd.arange(26*26*2).reshape(1,26*26, 1, 2),
            nd.arange(52*52*2).reshape(1,52*52, 1, 2)]


        """
        assert isinstance(anchors, (list, tuple))
        all_anchors = nd.concat(*[a.reshape(-1, 2) for a in anchors], dim=0) # shape = [3549, 2] 169 + 676 + 2704
        assert isinstance(offsets, (list, tuple))
        all_offsets = nd.concat(*[o.reshape(-1, 2) for o in offsets], dim=0)

        num_anchors = np.cumsum([a.size // 2 for a in anchors])  # num_anchors = array(3, 6, 9)
        num_offsets = np.cumsum([o.size // 2 for o in offsets])  # num_offsets = array(169, 169 + 676, 169 + 676 + 2704)
        _offsets = [0] + num_offsets.tolist()                    # _offsets    = [0, 169, 845, 3549]  
        assert isinstance(xs, (list, tuple))
        assert len(xs) == len(anchors) == len(offsets)  # 三者数量保持一致，一个anchor 对应一个offset


        # orig image size
        orig_height = img.shape[2]  # 416
        orig_width = img.shape[3]   # 416

        # 训练中暂时停止记录梯度，此时autograd.is_training 为True 
        with autograd.pause():
            # outputs 
            '''
                all_anchors.reshape --> [1, 9, 2]  这是一个grid cell的anchor
                all_offsets.reshape --> [3549, 1, 2]  # 这是所有的feature map
                相乘再expand_dims shape --> (1, 3549, 9, 2) # 每个grid cell 都有9个 anchor

                repeat --> shape_like.shape = [1, 3549, 9, 2]   

                weights.split(axis=-1, num_outputs=2)[0] --> [1, 3549, 9, 2]
                objectness shape = [1, 3549, 9, 1]
            '''
            shape_like = all_anchors.reshape((1, -1, 2)) * all_offsets.reshape(
                (-1, 1, 2)).expand_dims(0).repeat(repeats=gt_ids.shape[0], axis=0)

            ''' 全部初始化为0 '''
            center_targets = nd.zeros_like(shape_like)
            scale_targets = nd.zeros_like(center_targets)
            weights = nd.zeros_like(center_targets)
            objectness = nd.zeros_like(weights.split(axis=-1, num_outputs=2)[0])
            '''
            objectness.squeeze(axis=-1) 
                shape = [1, 3549, 9] 
            class_targets              
                shape = [gt_ids.shape[0], 3549, 9, self._num_class] 
                默认值全是-1，即忽略
                
            '''
            class_targets = nd.one_hot(objectness.squeeze(axis=-1), depth=self._num_class)
            class_targets[:] = -1  # prefill -1 for ignores
           
            '''
            # for each ground-truth, find the best matching anchor within the particular grid
            # for instance, center of object 1 reside in grid (3, 4) in (16, 16) feature map
            # then only the anchor in (3, 4) is going to be matched
                即，对于每个ground-truth寻找与之最匹配的anchor box，要在ground-truth所在的grid cell产生的box里寻找

            
            shift_gt_boxes 还是一个四角坐标，[1, M, 4]
 
            anchor_boxes shape = [1, 9,4] 前面两个数是表示是box的中心(0, 0)，后面两个数是priors的宽和高
            shift_anchor_boxes 化为四角坐标： [1, 9, 4]
            

            ious shape = [1,9, M]，M是具体某个gt-bbox里面的objness数量

            gtx shape:[1, M, 1]
            gty shape:[1, M, 1]
            gtw shape:[1, M, 1]
            gth shape:[1, M, 1]
            
            ''' 
            gtx, gty, gtw, gth = self.bbox2center(gt_boxes)  
            shift_gt_boxes = nd.concat(-0.5 * gtw, -0.5 * gth, 0.5 * gtw, 0.5 * gth, dim=-1)  # zero center  
            
            anchor_boxes = nd.concat(0 * all_anchors, all_anchors, dim=-1)  # zero center anchors
            shift_anchor_boxes = self.bbox2corner(anchor_boxes) # 又转换为四角坐标

            ious = nd.contrib.box_iou(shift_anchor_boxes, shift_gt_boxes).transpose((1, 0, 2))  # (1, 9, M)
            # real value is required to process, convert to Numpy
            '''
                IoU: 得到的是所有的anchor与每个gt_boxes的IoU,
                    ious.argmax(axis=1)得到的是M个gt_box与所有的anchor得到的最大IoU的索引。
                    这里 一个grid cell对应anchor 有9个， 但是只有一个anchor 最符合gt_box 。
                        nlayer = np.nonzero(num_anchors > match)[0][0] 
                    就是判断哪一层的anchor最符合
            '''
            matches = ious.argmax(axis=1).asnumpy()  # (B, M)
            valid_gts = (gt_boxes >= 0).asnumpy().prod(axis=-1)  # [B, M, 4]--> [B, M] 1则有效，如果是0则无效（即超过图像左上角边界）
            
            np_gtx, np_gty, np_gtw, np_gth = [x.asnumpy() for x in [gtx, gty, gtw, gth]]
            np_anchors = all_anchors.asnumpy()
            np_gt_ids = gt_ids.asnumpy()
            np_gt_mixratios = gt_mixratio.asnumpy() if gt_mixratio is not None else None
            # TODO(zhreshold): the number of valid gt is not a big number, therefore for loop
            # should not be a problem right now. Switch to better solution is needed.
            
            for b in range(matches.shape[0]):           # batch
                for m in range(matches.shape[1]):       # ground-truth 个数
                    if valid_gts[b, m] < 1:             # 无效的gt，忽略此次循环
                        break
                    match = int(matches[b, m])          # 取出与这这个gt最匹配的anchor的索引
                    nlayer = np.nonzero(num_anchors > match)[0][0]
                  
                    height = xs[nlayer].shape[2] # 13,26, 52
                    width = xs[nlayer].shape[3]
                    gtx, gty, gtw, gth = (np_gtx[b, m, 0], np_gty[b, m, 0],
                                          np_gtw[b, m, 0], np_gth[b, m, 0])

                    '''
                    index = _offsets[nlayer] + loc_y * width + loc_x ???
                            _offsets = [0, 169, 845, 3549],
                                grid cell的位置,从上一层开始计算，   即_offsets[nlayer]
                                loc_y * width  : 在每一阶段的feature map上， 大小是width * height ,  loc_y * width 表示位于第几行（因为一行有width个元素）
                                loc_x ： 表示第几列的位置。
                    gtx 是原图中的坐标，转换为相对每个grid cell的一个偏移量
                        1 首先需要确定gtx在当前feature map上的位置  = gtx/stride， 即：gtx / orig_width * width 
                        2  loc_x = int(gtx / orig_width * width) 即当前grid cell左上角的坐标位置
                        3  gtx / orig_width * width - loc_x，
                    同理,gty

                    w/h 
                        根据gtw/gth的位置计算公式： 
                        tw = log(gtw/pw)， 
                            其中pw是anchor的的width，由于tw是个比例系数，无论在哪个scale下的比例都是一致，
                            因此直接gtw/pw
                        th = log(gth/ph)， 其中ph是anchor的的height
                    
                        weights[b, index, match, :] = 2.0 - gtw * gth / orig_width / orig_height     
                        这个是在计算损失时候x,y,w,h的一个系数，为什么这么算，还真是不太理解
                    '''
                    loc_x = int(gtx / orig_width * width)   # loc_x  = gtx / stride  gtx是原图坐标，计算在当前feature map上落入的grid cell左上角的x位置
                    loc_y = int(gty / orig_height * height) # loc_x  = gty / stride                计算在当前feature map上落入的grid cell左上角的y位置
                    # write back to targets
                    index = _offsets[nlayer] + loc_y * width + loc_x
                    # shape = [B, 3549, 9, 2]  
                    center_targets[b, index, match, 0] = gtx / orig_width * width - loc_x    #  sigmoid(tx) 得到的是小于1的小数，相对当前fgrid cell左上角的偏移量
                    center_targets[b, index, match, 1] = gty / orig_height * height - loc_y  #  sigmoid(ty) 
                    scale_targets[b,  index, match, 0] = np.log(max(gtw, 1) / np_anchors[match, 0]) # tw
                    scale_targets[b,  index, match, 1] = np.log(max(gth, 1) / np_anchors[match, 1]) # th
                    weights[b, index, match, :] = 2.0 - gtw * gth / orig_width / orig_height       # ????  
                    objectness[b, index, match, 0] = (
                        np_gt_mixratios[b, m, 0] if np_gt_mixratios is not None else 1)
                    class_targets[b, index, match, :] = 0  
                    class_targets[b, index, match, int(np_gt_ids[b, m, 0])] = 1 # 实现one-hot编码

            # since some stages won't see partial anchors, so we have to slice the correct targets
            objectness = self._slice(objectness, num_anchors, num_offsets) 
            center_targets = self._slice(center_targets, num_anchors, num_offsets)
            scale_targets = self._slice(scale_targets, num_anchors, num_offsets)
            weights = self._slice(weights, num_anchors, num_offsets)
            class_targets = self._slice(class_targets, num_anchors, num_offsets)
        # 最后输出的维度都是:# [(B, 10647, 1 or 2)]
        # 其中，B = 1,  10647 = 13 * 13 * 3 +  26 * 26 * 3 + 52 * 52 * 3
        return objectness, center_targets, scale_targets, weights, class_targets  

    def _slice(self, x, num_anchors, num_offsets):
        """since some stages won't see partial anchors, so we have to slice the correct targets"""
        '''即，每个阶段的anchor都是不同的，一个阶段的anchor只能看到自己这个阶段的anchor,所有要切分下'''
        # x with shape (B, N, A, 1 or 2)
        anchors = [0] + num_anchors.tolist()
        offsets = [0] + num_offsets.tolist()
        ret = []
        for i in range(len(num_anchors)):
            # x[:, 0:169, 0:3, :] --> x shape = [B, 13 *13, 3, 1 or 2]
            y = x[:, offsets[i]:offsets[i+1], anchors[i]:anchors[i+1], :]
            # [(B, 13 * 13 * 3, 1 or 2),
            #  (B, 26 * 26 * 3, 1 or 2),
            #  (B, 52 * 52 * 3, 1 or 2)]
            ret.append(y.reshape((0, -3, -1)))  
         
        # [(B, 13 * 13 * 3 +  26 * 26 * 3 + 52 * 52 * 3, 1 or 2)]   
        # 把三个通道数数据联合在一起，这也是损失函数需要的格式
        return nd.concat(*ret, dim=1)


class YOLOV3DynamicTargetGeneratorSimple(gluon.HybridBlock):
  
    def __init__(self, num_class, ignore_iou_thresh, **kwargs):
        super(YOLOV3DynamicTargetGeneratorSimple, self).__init__(**kwargs)
        self._num_class = num_class  # voc:20, 
        self._ignore_iou_thresh = ignore_iou_thresh # ignore_iou_thresh:0.7
        self._batch_iou = BBoxBatchIOU()

    def hybrid_forward(self, F, box_preds, gt_boxes):   
        
        with autograd.pause():
            box_preds = box_preds.reshape((0, -1, 4))  
            '''
                box_preds：[batch, 3*(h*W*3), 4] 表示3个阶段的,每个阶段的一个grid cell预测3个bbox

            初始化全部是0
                objness_t：[batch, 3*(h*w*3), 1]  是否有物体，默认是0，表示没有
                center_t : [batch, 3*(h*w*3), 2]  
                scale_t  : [batch, 3*(h*w*3), 2]
                weight_t : [batch, 3*(h*w*3), 2]
            
            初始化为-1
                class_t  : [batch, 3*(h*w*3), 20] # voc  --> [batch, h*w*9, 20]
                    一个grid cell只是负责预测一个物体，不过生成9个anchor,分成三个阶段来采样信息，以实现对不同尺度的预测，
                    但是最终还是一个grid cell里。因此这个grid cell对应的预测class_t 是一个one_hot编码，只有一个为1，其余为0 

                    可以这么理解：
                        rcnn的9个anchor是在一个Feature map上采集得到的信息，而YOLOv3的9个anchor是在不同尺度的feature map上采集得到的信息，
                        然后融合在在一起，形成9个anchor，以检测当前grid cell的目标检测。

            输出的是一个box内容：
                1 object 是否有物体  + 1 box坐标（4个值） + weight_t(用于在计算损失时，x,y,w,h的系数)+ 一个one-hot编码

            '''
            objness_t = F.zeros_like(box_preds.slice_axis(axis=-1, begin=0, end=1)) # 对应置信度
            center_t = F.zeros_like(box_preds.slice_axis(axis=-1, begin=0, end=2))  # 中心坐标
            scale_t = F.zeros_like(box_preds.slice_axis(axis=-1, begin=0, end=2))   # 尺度比例因子
            weight_t = F.zeros_like(box_preds.slice_axis(axis=-1, begin=0, end=2))  
            class_t = F.ones_like(objness_t.tile(reps=(self._num_class))) * -1      # 对最后一个维度重复self._num_class次
            
            '''
                batch_ious = self._batch_iou(box_preds, gt_boxes) 
                    box_preds ： (B, N, 4) N = h*w*9
                    gt_boxes  ： (B, M, 4) M = h*w
                    batch_ious： (B, N, M) 
                ious_max = batch_ious.max(axis=-1, keepdims=True)
                    shape = [B, N, 1]
                    输出N=9个anchor与M个gt_bbox之间的iou，取出1个anchor与所有的gt_bbox的iou中最大的一个
                objness_t: 
                    shape = [B, N, 1]
                    要么是-1： 原本是正样本，之所以要忽略 是因为该grid cell的anchor已经检测正确，不参与训练，因为已经检测争取的样本对损失没有作用
                    要么是 0： 表示不忽略 参与训练。
                        这个忽略产生的影响是，那些预测为背景并且预测正确的anchor。因为背景不参与训练，如果已经预测准备，忽略与没都灭关系。
                        但是M个grid cell总有一些是背景，预测为背景，不需要训练。
            '''
            batch_ious = self._batch_iou(box_preds, gt_boxes)  # (B, N, M)  输出的M是 一个anchor与所有的gt_bbox的IoU。 N是anchor数量，B是batch
            ious_max = batch_ious.max(axis=-1, keepdims=True)  # (B, N, 1) 一个anchor与所有的gt_bbox中IoU最大的一个。
            objness_t = (ious_max > self._ignore_iou_thresh) * -1  # use -1 for ignored  
       
        return objness_t, center_t, scale_t, weight_t, class_t


class YOLOV3TargetMerger(gluon.HybridBlock):
    '''
        实际上是为了根据box_pred 取出对应的ground-truth值  为后面的训练准备。
    '''
    def __init__(self, num_class, ignore_iou_thresh, **kwargs):
        super(YOLOV3TargetMerger, self).__init__(**kwargs)
        self._num_class = num_class
        self._dynamic_target = YOLOV3DynamicTargetGeneratorSimple(num_class, ignore_iou_thresh)
        '''
            label_smooth是针对one-hot编码的一种改进措施，
            详细可参考：   
                《Bag of Tricks for Image Classification with Convolutional Neural Networks》
        '''
        self._label_smooth = False  

    def hybrid_forward(self, F, box_preds, gt_boxes, obj_t, centers_t, scales_t, weights_t, clas_t):

        with autograd.pause():
            dynamic_t = self._dynamic_target(box_preds, gt_boxes) 

            obj, centers, scales, weights, clas = zip(
                dynamic_t, [obj_t, centers_t, scales_t, weights_t, clas_t])
            '''
                mask obj[1] > 0  shape: [batch, h*w*9, 1]
                     obj[1] > 0  如果这个grid cell有对象相应位置为1，否则为0 
                     obj[1] <=0  表示这个grid cell没有对象，因为要么是被忽略的，要么是背景。被忽略的，其中心不在这个grid cell   
                objectness：
                    1：  正样本，表示这个框内确实存在目标
                    0：  负样本，表示上面的 ious_max < self._ignore_iou_thresh，这个位置不该忽略，纳入负样本损失计算
                    -1： 忽略不计算， 表示上面的 ious_max > self._ignore_iou_thresh 表示这个grid cell没有正样本，
                        同时也检测出是背景，那么损失计算就忽略，

                    如果：grid cell是正样本，但是ious_max > self._ignore_iou_thresh，那么这个位置其实忽略与否都不重要了，因为已经检测正确了。 
               
                mask2 = mask.tile(reps=(2,)) shape: [batch, 3*(h*w*3), 2]
                scale_targets = F.where(mask2, scales[1], scales[0])
                weights = F.where(mask2, weights[1], weights[0])
                    如果当前grid cell有物体, 那么就是取出该物体的中心坐标（wh, weight），没有的物体就设置为0。
                    weight_t 是在计算损失时，(x,y)和（weight, height)项的平衡系数

                mask3 = mask.tile(reps=(self._num_class,))  shape:[batch, 3*(h*w*3), 20]
                class_targets = F.where(mask3, clas[1], clas[0])
                    含义同上，如果有物体，那么就是取出其ground-truth 值(这是一个one-hot编码，只有一个是1，其余都是0)，否则就设置为0
                    获得的class_target， 如果当前grid  cell 有物体，那么就对应的class_ids就是其ground-truth值，否则就是-1 
                    
                    但是预测得one-hot可能不那么完全。

                class_mask = mask3 * (class_targets >= 0)  

                shape:[batch, 3*(h*w*3), 20] 

            上述返回值中，带有“-1”的是objness, class_targets
                      
            '''
            mask = obj[1] > 0 
            objectness = F.where(mask, obj[1], obj[0]) 
            mask2 = mask.tile(reps=(2,))
            center_targets = F.where(mask2, centers[1], centers[0])
            scale_targets = F.where(mask2, scales[1], scales[0])
            weights = F.where(mask2, weights[1], weights[0])  

            mask3 = mask.tile(reps=(self._num_class,))
            class_targets = F.where(mask3, clas[1], clas[0])  # 就是一个one-hot编码
            
            class_mask = mask.tile(reps=(self._num_class,)) * (class_targets >= 0)
            return [F.stop_gradient(x) for x in [objectness, center_targets, scale_targets,
                                                 weights, class_targets, class_mask]]
